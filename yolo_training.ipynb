{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236cb460",
   "metadata": {},
   "source": [
    "AdÄ±nÄ±z: GÃ¶khan\n",
    "SoyadÄ±nÄ±z: YAPICI\n",
    "NumaranÄ±z:2112729006\n",
    "GitHub Repo BaÄŸlantÄ±sÄ±:https://github.com/gkhan5252/Yolov8_i-e_Nesne_Tespit_Uygulamasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfd004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KÃœTÃœPHANELERI YÃœKLEÄ°\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ultralytics\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyyaml\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"opencv-python\"])\n",
    "\n",
    "import os, zipfile, shutil, yaml, torch, cv2, random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸš€ YOLOV8 COLAB EÄÄ°TÄ°MÄ° - BAÅLANIYOR\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# 1. ORTAM HAZIRLAMA\n",
    "print(\"1ï¸âƒ£  ORTAM HAZIRLANIYORU...\")\n",
    "print(f\"   GPU: {torch.cuda.is_available()}\")\n",
    "print(\"   âœ… KÃ¼tÃ¼phaneler yÃ¼klendi\\n\")\n",
    "\n",
    "# 2. DATASET Ã‡IKARMA\n",
    "print(\"2ï¸âƒ£  DATASET Ã‡IKARILIYOR...\")\n",
    "dataset_zip = Path('/content/Dataset1.zip')\n",
    "if not dataset_zip.exists():\n",
    "    print(\"   âš ï¸  Dataset1.zip bulunamadÄ±!\")\n",
    "    print(\"   ğŸ“ Files sekmesinden Dataset1.zip yÃ¼kle ve tekrar Ã§alÄ±ÅŸtÄ±r\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"   âœ… ZIP dosyasÄ± bulundu, Ã§Ä±karÄ±lÄ±yor...\")\n",
    "with zipfile.ZipFile(str(dataset_zip), 'r') as z:\n",
    "    z.extractall('/content/')\n",
    "\n",
    "# AyrÄ± veri setlerini bul (catal, kasik, tabak)\n",
    "separate_datasets = []\n",
    "for name in ['catal', 'kasik', 'tabak']:\n",
    "    dataset_path = Path(f'/content/{name}.v1i.yolov8') or Path(f'/content/{name}')\n",
    "    if dataset_path.exists():\n",
    "        train_path = dataset_path / 'train' / 'images'\n",
    "        if train_path.exists():\n",
    "            separate_datasets.append((name, dataset_path))\n",
    "            print(f\"   âœ… {name} veri seti bulundu\")\n",
    "\n",
    "if not separate_datasets:\n",
    "    print(\"   âš ï¸  HATA: catal, kasik, tabak veri setleri bulunamadÄ±!\")\n",
    "    print(\"   Mevcut klasÃ¶rler:\")\n",
    "    for item in Path('/content').iterdir():\n",
    "        if item.is_dir() and not item.name.startswith('.'):\n",
    "            print(f\"     - {item.name}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# UNIFIED DATASET OLUÅTUR\n",
    "print(\"\\n   ğŸ“¦ BirleÅŸtirilmiÅŸ veri seti oluÅŸturuluyor...\")\n",
    "unified_dir = Path('/content/yolo_dataset')\n",
    "unified_dir.mkdir(exist_ok=True)\n",
    "\n",
    "train_images = unified_dir / 'train' / 'images'\n",
    "train_labels = unified_dir / 'train' / 'labels'\n",
    "val_images = unified_dir / 'val' / 'images'\n",
    "val_labels = unified_dir / 'val' / 'labels'\n",
    "\n",
    "train_images.mkdir(parents=True, exist_ok=True)\n",
    "train_labels.mkdir(parents=True, exist_ok=True)\n",
    "val_images.mkdir(parents=True, exist_ok=True)\n",
    "val_labels.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SÄ±nÄ±f eÅŸlemesi\n",
    "class_mapping = {'catal': 0, 'tabak': 1, 'kasik': 2}\n",
    "\n",
    "total_train = 0\n",
    "total_val = 0\n",
    "\n",
    "# Her veri setini iÅŸle\n",
    "all_train_files = []\n",
    "\n",
    "for class_name, dataset_path in separate_datasets:\n",
    "    class_id = class_mapping[class_name]\n",
    "\n",
    "    # Train gÃ¶rÃ¼ntÃ¼leri kopyala\n",
    "    src_train_imgs = dataset_path / 'train' / 'images'\n",
    "    if src_train_imgs.exists():\n",
    "        for img_file in src_train_imgs.glob('*.*'):\n",
    "            shutil.copy(str(img_file), str(train_images / img_file.name))\n",
    "            total_train += 1\n",
    "\n",
    "            # Label dosyasÄ±nÄ± kopyala ve sÄ±nÄ±f ID'sini gÃ¼ncelle\n",
    "            label_src = dataset_path / 'train' / 'labels' / f'{img_file.stem}.txt'\n",
    "            label_dst = train_labels / f'{img_file.stem}.txt'\n",
    "            if label_src.exists():\n",
    "                with open(label_src, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                with open(label_dst, 'w') as f:\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if parts:\n",
    "                            parts[0] = str(class_id)\n",
    "                            f.write(' '.join(parts) + '\\n')\n",
    "                all_train_files.append((img_file.name, f'{img_file.stem}.txt'))\n",
    "\n",
    "    # Validation gÃ¶rÃ¼ntÃ¼leri kopyala (varsa)\n",
    "    src_val_imgs = dataset_path / 'val' / 'images'\n",
    "    if src_val_imgs.exists():\n",
    "        for img_file in src_val_imgs.glob('*.*'):\n",
    "            shutil.copy(str(img_file), str(val_images / img_file.name))\n",
    "            total_val += 1\n",
    "\n",
    "            label_src = dataset_path / 'val' / 'labels' / f'{img_file.stem}.txt'\n",
    "            label_dst = val_labels / f'{img_file.stem}.txt'\n",
    "            if label_src.exists():\n",
    "                with open(label_src, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                with open(label_dst, 'w') as f:\n",
    "                    for line in lines:\n",
    "                        parts = line.strip().split()\n",
    "                        if parts:\n",
    "                            parts[0] = str(class_id)\n",
    "                            f.write(' '.join(parts) + '\\n')\n",
    "\n",
    "# EÄŸer validation klasÃ¶rÃ¼ boÅŸsa, eÄŸitimden %20 taÅŸÄ±\n",
    "if total_val == 0 and total_train > 0:\n",
    "    import random\n",
    "    random.shuffle(all_train_files)\n",
    "    split_idx = int(total_train * 0.2)  # %20 validation\n",
    "\n",
    "    for img_name, label_name in all_train_files[:split_idx]:\n",
    "        shutil.move(str(train_images / img_name), str(val_images / img_name))\n",
    "        shutil.move(str(train_labels / label_name), str(val_labels / label_name))\n",
    "        total_train -= 1\n",
    "        total_val += 1\n",
    "\n",
    "print(f\"   âœ… {total_train} eÄŸitim + {total_val} doÄŸrulama gÃ¶rÃ¼ntÃ¼sÃ¼ birleÅŸtirildi\\n\")\n",
    "\n",
    "dataset_dir = unified_dir\n",
    "\n",
    "# 3. DATA.YAML HAZIRLAMA\n",
    "print(\"3ï¸âƒ£  CONFIG HAZIRLANIYOR...\")\n",
    "data_yaml = dataset_dir / 'data.yaml'\n",
    "\n",
    "with open(data_yaml, 'w') as f:\n",
    "    f.write(\"\"\"path: /content/yolo_dataset\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: 3\n",
    "names:\n",
    "  0: catal\n",
    "  1: tabak\n",
    "  2: kasik\n",
    "\"\"\")\n",
    "\n",
    "print(\"   âœ… data.yaml oluÅŸturuldu\")\n",
    "\n",
    "train_imgs = len(list((dataset_dir / 'train' / 'images').glob('*.*')))\n",
    "val_imgs = len(list((dataset_dir / 'val' / 'images').glob('*.*')))\n",
    "\n",
    "print(f\"   SÄ±nÄ±flar: catal, tabak, kasik\")\n",
    "print(f\"   EÄŸitim: {train_imgs} | DoÄŸrulama: {val_imgs}\")\n",
    "print(f\"   âœ… TamamlandÄ±\\n\")\n",
    "\n",
    "# 4. MODEL EÄÄ°TÄ°MÄ°\n",
    "print(\"4ï¸âƒ£  MODEL EÄÄ°TÄ°MÄ° BAÅLIYOR (40 epoch)...\")\n",
    "print(\"   â³ LÃ¼tfen bekleyin...\\n\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else 'cpu'\n",
    "batch = 16 if torch.cuda.is_available() else 8\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "results = model.train(\n",
    "    data=str(data_yaml),\n",
    "    epochs=40,\n",
    "    imgsz=640,\n",
    "    batch=batch,\n",
    "    patience=20,\n",
    "    device=device,\n",
    "    verbose=False,\n",
    "    save=True,\n",
    "    project='/content/runs/detect',\n",
    "    name='utensil_detection'\n",
    ")\n",
    "\n",
    "print(\"   âœ… EÄŸitim TamamlandÄ±\\n\")\n",
    "\n",
    "# 5. METRIKLERI GÃ–STER\n",
    "print(\"5ï¸âƒ£  MODEL METRÄ°KLERÄ°...\")\n",
    "\n",
    "best_path = Path('/content/runs/detect/utensil_detection/weights/best.pt')\n",
    "best_model = YOLO(str(best_path))\n",
    "\n",
    "val_results = best_model.val(data=str(data_yaml))\n",
    "\n",
    "print(f\"   mAP50:    {val_results.box.map50:.4f}\")\n",
    "print(f\"   mAP50-95: {val_results.box.map:.4f}\")\n",
    "print(\"   âœ… TamamlandÄ±\\n\")\n",
    "\n",
    "# 6. TEST Ã–RNEÄÄ°\n",
    "print(\"6ï¸âƒ£  TEST Ã–RNEÄÄ°...\")\n",
    "\n",
    "train_dir = dataset_dir / 'train' / 'images'\n",
    "test_imgs = list(train_dir.glob('*.*'))\n",
    "\n",
    "if test_imgs:\n",
    "    test_img = random.choice(test_imgs)\n",
    "    print(f\"   Test: {test_img.name}\")\n",
    "\n",
    "    pred = best_model.predict(str(test_img), conf=0.4, verbose=False)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    result_img = pred[0].plot()\n",
    "    result_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n",
    "    ax.imshow(result_rgb)\n",
    "    ax.set_title('YOLOv8 Tespit Sonucu')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    count = sum(len(r.boxes) for r in pred)\n",
    "    print(f\"   âœ… {count} nesne tespit edildi\\n\")\n",
    "\n",
    "# 7. DOSYA Ä°NDÄ°RME\n",
    "print(\"7ï¸âƒ£  DOSYALARI Ä°NDÄ°RME...\")\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "out_model = Path('/content/best_utensil_colab.pt')\n",
    "shutil.copy(str(best_path), str(out_model))\n",
    "size = out_model.stat().st_size / (1024**2)\n",
    "\n",
    "print(f\"   ğŸ“¥ best_utensil_colab.pt ({size:.2f} MB)\")\n",
    "files.download(str(out_model))\n",
    "\n",
    "csv = Path('/content/runs/detect/utensil_detection/results.csv')\n",
    "if csv.exists():\n",
    "    print(f\"   ğŸ“¥ results.csv\")\n",
    "    files.download(str(csv))\n",
    "\n",
    "conf = Path('/content/runs/detect/utensil_detection/confusion_matrix.png')\n",
    "if conf.exists():\n",
    "    print(f\"   ğŸ“¥ confusion_matrix.png\")\n",
    "    files.download(str(conf))\n",
    "\n",
    "res = Path('/content/runs/detect/utensil_detection/results.png')\n",
    "if res.exists():\n",
    "    print(f\"   ğŸ“¥ results.png\")\n",
    "    files.download(str(res))\n",
    "\n",
    "print(\"   âœ… TamamlandÄ±\\n\")\n",
    "\n",
    "# 8. SELESAI\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… TÃœM Ä°ÅLEMLER TAMAMLANDI!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“Œ Ã–NEMLÄ°:\")\n",
    "print(\"   1. best_utensil_colab.pt dosyasÄ±nÄ± kaydet\")\n",
    "print(\"   2. Proje klasÃ¶rÃ¼ne kopyala (d:\\\\model egitim\\\\)\")\n",
    "print(\"   3. gui_app.py'de model adÄ±nÄ± gÃ¼ncelle:\")\n",
    "print(\"      model = YOLO('best_utensil_colab.pt')\")\n",
    "print(\"   4. python gui_app.py Ã§alÄ±ÅŸtÄ±r\\n\")\n",
    "print(\"ğŸ‰ BaÅŸarÄ±!\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
